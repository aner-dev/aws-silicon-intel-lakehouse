П Ultra-Prompt: AWS Lakehouse Development (Continuidad)
Contexto del Proyecto: "Act煤a como un Senior Data Engineer & Platform Architect. Estamos desarrollando un Lakehouse moderno en AWS (simulado localmente y listo para nube) que procesa datos financieros de alta frecuencia. El objetivo es evolucionar el proyecto anterior hacia un stack basado en Intel/Silicon, optimizado para c贸mputo pesado.

Estado de la Infraestructura y Troubleshooting realizado:

Entorno de Ejecuci贸n: Usamos Astro CLI sobre Podman.

Red (Cr铆tico): Se identific贸 y resolvi贸 un cuello de botella de red donde el MTU por defecto de la interfaz de Podman (65,000) causaba fragmentaci贸n de paquetes en llamadas a APIs externas. Hemos estandarizado a MTU 1500 en redes personalizadas.

Docker & Java: El runtime de Airflow (basado en Debian Bookworm) ha sido personalizado exitosamente. Instalamos OpenJDK 17 headless y configuramos el entorno para que PySpark 3.5.0 pueda ejecutarse dentro de los workers de Airflow sin conflictos de dependencias, gestionando todo mediante UV para una resoluci贸n de paquetes ultrarr谩pida.

Bloqueo Actual: Estamos lidiando con un error de manifest unknown al levantar el cluster de Spark en el docker-compose.override.yml. Estamos migrando a im谩genes verificadas de Bitnami (Spark 3.5.0) para asegurar compatibilidad.

Arquitectura de Datos (Medallion & Lakehouse):

Storage: Implementaci贸n de RustFS (S3-compatible) para emular el Data Lake de AWS.

Engine: Dualidad t茅cnica. Usamos Polars para transformaciones r谩pidas de memoria (Silver Layer) aprovechando Apache Arrow, y Spark para el procesamiento distribuido de grandes vol煤menes.

Modeling: Esquema en estrella (Star Schema) en la capa Gold, gestionado por dbt.

Orchestration: Airflow mediante Data-Aware Scheduling (Datasets) para desacoplar la ingesta de la transformaci贸n.

Tu Misi贸n para esta sesi贸n:

Fix de Infraestructura: Revisar el docker-compose.override.yml para mapear correctamente las im谩genes de bitnami/spark:3.5.0 y asegurar que el Master y el Worker se comuniquen en la misma red que Airflow.

Ingesta Pro (Bronze): Dise帽ar un DAG de Airflow que use Dynamic Task Mapping para procesar m煤ltiples tickers de acciones en paralelo, persistiendo el JSON crudo en el bucket de RustFS.

Dise帽o de la Capa Silver: Crear el template de transformaci贸n con Polars. Necesito que el c贸digo maneje la serializaci贸n Arrow para pasar datos de la extracci贸n al procesamiento sin el overhead de Pandas.

Validaci贸n de Calidad: Configurar los primeros tests de dbt-expectations para asegurar que no entren nulos en las columnas de precios ajustados.

Documentaci贸n t茅cnica de referencia:

Engine: Spark 3.5.0 / Python 3.13.11 / Polars (Rust-backed).

Storage: S3 API / Parquet format.

Networking: Podman Custom Bridge (MTU 1500).

驴Cu谩l es la estrategia m谩s eficiente para configurar el SparkSubmitOperator en Airflow de modo que reconozca los nodos del cluster externo que estamos levantando en el override?"
